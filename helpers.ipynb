{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting USGShydro.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile USGShydro.py\n",
    "import rainfallrunoff as RR\n",
    "import gzip\n",
    "from urllib.request import urlopen, Request\n",
    "import sys\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from shapely.geometry import Point,Polygon\n",
    "import descartes\n",
    "\n",
    "from bokeh.io import show, output_notebook; \n",
    "from bokeh.plotting import figure; \n",
    "from bokeh.models import ColumnDataSource\n",
    "output_notebook()\n",
    "\n",
    "class Hydrosite():\n",
    "    '''make parent class hydrosite, child will be hydrositedata, and grandchild is hydrositedatamodel. '''\n",
    "    def __init__(self, site):\n",
    "        self.site='sites='+site\n",
    "        self.sitecode=site[-8:]\n",
    "        self.sitedirectory='data/usgs-huc8-'+self.sitecode \n",
    "        if not os.path.exists(self.sitedirectory):\n",
    "            os.makedirs(self.sitedirectory)\n",
    "\n",
    "    \n",
    "class Hydrositedata(Hydrosite): \n",
    "    '''make child of Hydrosite that has its own child Hydrositedatamodel.\n",
    "    Create attributes self.start and self.end the start and times.\n",
    "    Create attribute self.paramlist, the list of requested time series\n",
    "    Run method self.get_data, then self.extractfromxml, then self.timematchcheck \n",
    "    methods not called at runtime\n",
    "    simpleplot() create a simple plot of rainfall vs runoff\n",
    "    geoplot() plots the point and the drainage basin\n",
    "    '''\n",
    "    def __init__(self, site, start, end, paramlist):\n",
    "        super().__init__(site)\n",
    "        self.start='startDT='+start\n",
    "        self.end='endDT='+end\n",
    "        self.paramlist=paramlist\n",
    "        self.get_data()\n",
    "        self.extractfromxml()\n",
    "        self.timematchcheck()\n",
    "        self.timestepcheck()\n",
    "        self.tonumpy()\n",
    "        \n",
    "        \n",
    "    def extractfromxml(self):\n",
    "        \"\"\"Take the time and values for each series from the xml to python lists with\n",
    "        observations matched by time or else omitted from the new list. creates a new attribute\n",
    "        called self.extracted with a column for each series and each row contains a (time,value) tuple.\n",
    "        Create Attributes:\n",
    "        self.extracted contains a list of series and each series is a list of\n",
    "        (time, value) tuples \n",
    "        self.datatracker a list of the length of each list of series\n",
    "        self.obs_idlist contains basic meta-data for each series downloaded\n",
    "        self.latlon contains a list of strings with latitude and longitude for each series\n",
    "        \"\"\"\n",
    "        \"\"\"Note: xmllint --format file.xml in the linux terminal is used to view the structure of a \n",
    "        downloaded xml document\n",
    "        \"\"\"\n",
    "        namespace={'ns0':\"http://www.opengis.net/waterml/2.0\",\n",
    "           'ns1':\"http://www.opengis.net/gml/3.2\",\n",
    "           'ns3':\"http://www.w3.org/1999/xlink\",\n",
    "           'ns4':\"http://www.opengis.net/om/2.0\",\n",
    "           'ns5':\"http://www.opengis.net/sampling/2.0\" ,\n",
    "           'ns6':\"http://www.opengis.net/samplingSpatial/2.0\",\n",
    "           'ns7':\"http://www.opengis.net/swe/2.0\"} \n",
    "        #add feature: automatically make the namespace dictionary automatic by pulling from begining of xml file\n",
    "        extracted=[];j=-1;tracker=[];obs_idlist=[]; latlon=[];latlon_crs=[]; sitemetadata=[]\n",
    "        for elem in self.root.findall('ns0:observationMember',namespace):\n",
    "            obs_idlist.append(elem.find('ns4:OM_Observation',namespace).attrib)\n",
    "            for elem2 in elem.findall('ns4:OM_Observation',namespace):\n",
    "                tracker.append(0)#initialize the next series\n",
    "                extracted.append([])\n",
    "                j+=1#j is indexing each series\n",
    "                elem3=elem2.find('ns4:featureOfInterest',namespace)\n",
    "                sitemetadata.append(elem3.attrib['{http://www.w3.org/1999/xlink}title'])\n",
    "                elem_latlon=elem3.find('ns0:MonitoringPoint',namespace)\\\n",
    "                    .find('ns6:shape',namespace)\\\n",
    "                    .find('ns1:Point',namespace)\\\n",
    "                    .find('ns1:pos',namespace)\n",
    "                latlon.append(elem_latlon.text)\n",
    "                latlon_crs.append(elem_latlon.attrib['srsName'][-9:])\n",
    "                for elem3 in elem2.findall('ns4:result',namespace):\n",
    "                    for elem4 in elem3.findall('ns0:MeasurementTimeseries',namespace):\n",
    "                        for elem5 in elem4.findall('ns0:point',namespace):\n",
    "                            for elem6 in elem5.findall('ns0:MeasurementTVP',namespace):\n",
    "                                time=elem6.find('ns0:time',namespace)\n",
    "                                val=elem6.find('ns0:value',namespace)\n",
    "                                extracted[j].append((time.text,val.text))\n",
    "                                tracker[j]+=1\n",
    "        self.sitemetadata=sitemetadata\n",
    "        self.latlon=latlon\n",
    "        self.latlon_crs=latlon_crs\n",
    "        self.extracted=extracted\n",
    "        self.datatracker=tracker #a list of counts of observations for each time,value pair\n",
    "        self.obs_idlist=obs_idlist\n",
    "        \n",
    "    def geoplot(self):\n",
    "        \"\"\"creates a plot of the site location on a map with the drainage basin and eventually NLCD landcover\n",
    "        \"\"\"\n",
    "        j=len(self.latlon)\n",
    "        self.df=pd.DataFrame([[self.latlon[j][-11:],self.latlon[j][:11],self.latlon_crs[j],self.sitemetadata[j]] for j in range(j)],columns=[\"longitude\",\"latitude\",\"CRS\",\"site_name\"])\n",
    "        #wmsurl=https://smallscale.nationalmap.gov/arcgis/services/LandCover/MapServer/WMSServer?request=GetCapabilities&service=WMS\n",
    "        \n",
    "        \n",
    "    def get_data(self):\n",
    "        \"\"\"create self.requesturl, a url based on site# and parameters.\n",
    "        create self.datapath to check if data from self.requesturl has already been downloaded\n",
    "        Use locally stored xml data if available or download the data if not.\n",
    "        create self.data containing the unzipped gzip string data.\n",
    "        create self.root that contains the root of the element tree .\n",
    "        \"\"\"\n",
    "        baseurl='https://waterservices.usgs.gov/nwis/iv/?'\n",
    "        theformat='format=waterml,2.0'\n",
    "        parameter='parameterCd='+','.join(self.paramlist)\n",
    "        urlsuffix=theformat+'&'+self.site+'&'+self.start+'&'+self.end+'&'+parameter+'&'+'siteStatus=all'\n",
    "        self.requesturl=baseurl+urlsuffix\n",
    "        self.datapath=os.path.join(self.sitedirectory,urlsuffix+'.xml')#put these details in a companion file and simplify file name\n",
    "        if os.path.exists(self.datapath):\n",
    "            self.data=ET.parse(self.datapath) #add try clause?\n",
    "            self.root=self.data.getroot() \n",
    "        else:    \n",
    "            response=urlopen(Request(self.requesturl,headers={\"Accept-Encoding\": \"gzip\"})) \n",
    "            self.data=gzip.open(response, 'rb').read()\n",
    "            self.root=ET.fromstring(self.data)\n",
    "            savefile=open(self.datapath,'w')\n",
    "            savefile.write(ET.tostring(self.root).decode(\"utf-8\"))\n",
    "            savefile.close()\n",
    "    \n",
    "    def simpleplot(self):\n",
    "        gageht=self.data_array[:,2]-np.amin(self.data_array[:,2])\n",
    "        time=self.data_array[:,0]\n",
    "        precip=self.data_array[:,1]\n",
    "        p=figure(title='rainfall and gageheight over time', plot_width=900, plot_height=500)\n",
    "        p.xaxis.axis_label = 'time(days)'\n",
    "        p.scatter(time,precip,size=precip/np.amax(precip)*7+2,color='red',alpha=0.6,legend='precipitation')\n",
    "        p.line(time,precip,color='red',alpha=0.6,legend='precipitation')\n",
    "        p.scatter(time,gageht,size=2,color='blue',legend='gage height')\n",
    "        p.line(time,gageht,color='blue',legend='gage height')\n",
    "        p.legend.location = \"top_left\"\n",
    "        p.yaxis.visible=False\n",
    "        show(p)\n",
    "    \n",
    "    def timestepcheck(self):\n",
    "        \"\"\"if the number of time periods is T then create attribute self.timestep, a list of T-1 time steps\n",
    "        Then create attribute self.allstepeven and set it to 1 if all items in self.timestep are equal.\n",
    "        add threshold?\n",
    "        todo: handle allmatch==0\n",
    "        \"\"\"\n",
    "        self.allstepseven=0\n",
    "        self.t_format='%Y-%m-%dT%H:%M:%S%z'\n",
    "        stepcount=len(self.matchlog)-1 #minus 1 because it is a difference\n",
    "        timestep=[[0] for _ in range(stepcount)]\n",
    "        if self.allmatch==1:\n",
    "            for i in range(stepcount):\n",
    "                timestep[i]=datetime.datetime.strptime(self.extracted[0][i+1][0],self.t_format)\n",
    "            for i in range(stepcount):\n",
    "                timestep[i]-=datetime.datetime.strptime(self.extracted[0][i][0],self.t_format)\n",
    "            self.timestep=timestep\n",
    "            self.allstepseven=all([j==timestep[0] for j in timestep])\n",
    "        else:sys.exit(\"error from allmatch==0\")\n",
    "        if self.allstepseven==1: print('all time steps are evenly spaced')\n",
    "        else: print('not all time steps are evenly spaced')\n",
    "    \n",
    "    def timematchcheck(self):\n",
    "        \"\"\"create an attribute self.matchlog that contains a column\n",
    "        for comparing times for series 1 with series 2, then series 1 and series 3, and so on\n",
    "        the rows of self.matchlog  are 1 if all series in that row have the same time and 0 \n",
    "        if any are not a match.\n",
    "        create attribute self.allmatch which is 1 if all values have a matching time and 0 if not.\n",
    "        add feature: handle data that is not synchronized across each row\n",
    "        \"\"\"\n",
    "        matchlog=[]\n",
    "        self.allmatch=1\n",
    "        for i in range(self.datatracker[0]):\n",
    "            matchlog.append([])\n",
    "            for j in range(len(self.datatracker)-1): #j-1 because we have 1 less comparison than series\n",
    "                matchlog[i].append(1) #start all matches as true\n",
    "                if self.extracted[0][i][0]==self.extracted[j+1][i][0]: #j+1 to avoid comparing first series to itself\n",
    "                    matchlog[i][j]=matchlog[i][j]*1 #this will maintian the zero or 1 value\n",
    "                else: \n",
    "                    matchlog[i][j]=0 #this will force the match value to zero if any times don't match.\n",
    "                    self.allmatch=0\n",
    "                    print('not all series have matching times from start to end.')\n",
    "                    print('view attribute *.matchlog to see discrepancies from first series')\n",
    "        self.matchlog=matchlog\n",
    "        if self.allmatch==1: print('all series have matching times from start to end')\n",
    "        \n",
    "            \n",
    "             \n",
    "    def tonumpy(self):\n",
    "        \"\"\"create self.data_array a numpy array with an observation on each row containing a time\n",
    "        column measuring days since the first obseration followed by each series\n",
    "        \"\"\"\n",
    "        if self.allmatch==1:\n",
    "            n=len(self.matchlog)\n",
    "            k=len(self.matchlog[0])+2 #+1 for time column, +1 more since matchlog is nx1 for 2 series\n",
    "            print('The request has returned {} observations for {} series'.format(n,k-1))\n",
    "            self.data_array=np.ones([n,k])\n",
    "            startdate=datetime.datetime.strptime(self.extracted[0][0][0],self.t_format)\n",
    "            startyear=startdate.year\n",
    "            for i in range(n):\n",
    "                timediffs=datetime.datetime.strptime(self.extracted[0][i][0],self.t_format)-startdate\n",
    "                self.data_array[i,0]=timediffs.days+timediffs.seconds/60/60/24 #convert to days\n",
    "                for j in range(k-1): #k-1 because time is set\n",
    "                    try: self.data_array[i,j+1]=float(self.extracted[j][i][1])\n",
    "                    except:self.data_array[i,j+1]=np.nan\n",
    "        else: import sys;sys.exit(\"error from allmatch==0\")        \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "class Hydrositedatamodel(Hydrositedata):\n",
    "    '''makes subclass of hydrosite,subclass of hydrositedata\n",
    "    '''\n",
    "    def __init__(self, site, start, end, paramlist, modelfeatures):\n",
    "        super().__init__(site,start,end,paramlist)\n",
    "        self.modelfeatures=modelfeatures\n",
    "        self.model=RR.RRtimeseries(self.data_array, modelfeatures)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rainfallrunoff.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rainfallrunoff.py\n",
    "\n",
    "import numpy as np\n",
    "class RRtimeseries():\n",
    "    '''take in column of dates, rainfall, and runoff and builds distributed lag model'''\n",
    "    def __init__(self,data,modelfeatures):\n",
    "        self.data=data\n",
    "        self.modelfeatures=modelfeatures\n",
    "        if modelfeatures['RRmodeltype']=='distributed_lag':\n",
    "            if modelfeatures['local']=='no':\n",
    "                maxlag=modelfeatures['maxlag']\n",
    "                self.distlagmodel()\n",
    "        else: print('other')\n",
    "        \n",
    "    def distlagmodel(self):\n",
    "        n,k=data.shape()\n",
    "        \n",
    "        self.lagprecip=self.lagmaker(data[:,1],maxlags)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def lagmaker(self,dataseries,maxlag):  \n",
    "        lagprecip=np.ones(n+maxlag,maxlag+1) #+1 b/c 0...maxlag\n",
    "        for i in range(maxlag+1):\n",
    "            lagprecip[[i:n],i]=data[:,1]\n",
    "        self.lagprecip=lagprecip[maxlag:(n+maxlag),:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
