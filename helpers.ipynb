{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting USGShydro.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile USGShydro.py\n",
    "import gzip\n",
    "from urllib.request import urlopen, Request\n",
    "import sys\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "class Hydrosite():\n",
    "    '''make parent class hydrosite, child will be hydrositedata, and grandchild is hydrositedatamodel. '''\n",
    "    def __init__(self, site):\n",
    "        self.site=site\n",
    "        self.sitecode=site[-8:]\n",
    "        self.sitedirectory='data/usgs-huc8-'+self.sitecode \n",
    "        if not os.path.exists(self.sitedirectory):\n",
    "            os.makedirs(self.sitedirectory)\n",
    "\n",
    "    \n",
    "class Hydrositedata(Hydrosite): \n",
    "    '''make child of Hydrosite that has its own child Hydrositedatamodel.\n",
    "    Create attributes self.start and self.end the start and times.\n",
    "    Create attribute self.paramlist, the list of requested time series\n",
    "    Run method self.get_data, then self.extractfromxml, then self.timematchcheck    \n",
    "    '''\n",
    "    def __init__(self, site, start, end, paramlist):\n",
    "        super().__init__(site)\n",
    "        self.start=start\n",
    "        self.end=end\n",
    "        self.paramlist=paramlist\n",
    "        self.get_data()\n",
    "        self.extractfromxml()\n",
    "        self.timematchcheck()\n",
    "        self.timestepcheck()\n",
    "        self.tonumpy()\n",
    "        \n",
    "    def get_data(self):\n",
    "        \"\"\"create self.requesturl, a url based on site# and parameters.\n",
    "        create self.datapath to check if data from self.requesturl has already been downloaded\n",
    "        Use locally stored xml data if available or download the data if not.\n",
    "        create self.data containing the unzipped gzip string data.\n",
    "        create self.root that contains the root of the element tree .\n",
    "        \"\"\"\n",
    "        baseurl='https://waterservices.usgs.gov/nwis/iv/?'\n",
    "        theformat='format=waterml,2.0'\n",
    "        parameter='parameterCd='+','.join(self.paramlist)\n",
    "        urlsuffix=theformat+'&'+self.site+'&'+self.start+'&'+self.end+'&'+parameter+'&'+'siteStatus=all'\n",
    "        self.requesturl=baseurl+urlsuffix\n",
    "        self.datapath=os.path.join(self.sitedirectory,urlsuffix+'.xml')#put these details in a companion file and simplify file name\n",
    "        if os.path.exists(self.datapath):\n",
    "            self.data=ET.parse(self.datapath) #add try clause?\n",
    "            self.root=self.data.getroot() \n",
    "        else:    \n",
    "            response=urlopen(Request(self.requesturl,headers={\"Accept-Encoding\": \"gzip\"})) \n",
    "            self.data=gzip.open(response, 'rb').read()\n",
    "            self.root=ET.fromstring(self.data)\n",
    "            savefile=open(self.datapath,'w')\n",
    "            savefile.write(ET.tostring(self.root).decode(\"utf-8\"))\n",
    "            savefile.close()\n",
    "         \n",
    "    def tonumpy(self):\n",
    "        if self.allmatch==1:\n",
    "            n=len(self.matchlog)\n",
    "            k=len(self.matchlog[0])+2 #+1 for time column, +1 more since matchlog is nx1 for 2 series\n",
    "            print(n,k)\n",
    "            self.data_array=np.ones([n,k])\n",
    "            startdate=datetime.datetime.strptime(self.extracted[0][0][0],self.t_format)\n",
    "            for i in range(n):\n",
    "                timediffs=datetime.datetime.strptime(self.extracted[0][i][0],self.t_format)-startdate\n",
    "                self.data_array[i,0]=timediffs.seconds/60/60 #convert to hours\n",
    "                for j in range(k-1): #k-1 because time is set\n",
    "                    self.data_array[i,j+1]=float(self.extracted[j][i][1])\n",
    "        else: import sys;sys.exit(\"error from allmatch==0\")        \n",
    "    \n",
    "    def timestepcheck(self):\n",
    "        \"\"\"if the number of time periods is T then create attribute self.timestep, a list of T-1 time steps\n",
    "        Then create attribute self.allstepeven and set it to 1 if all items in self.timestep are equal.\n",
    "        add threshold?\n",
    "        todo: handle allmatch==0\n",
    "        \"\"\"\n",
    "        self.allstepseven=0\n",
    "        self.t_format='%Y-%m-%dT%H:%M:%S%z'\n",
    "        stepcount=len(self.matchlog)-1 #minus 1 because it is a difference\n",
    "        timestep=[[0] for _ in range(stepcount)]\n",
    "        if self.allmatch==1:\n",
    "            for i in range(stepcount):\n",
    "                timestep[i]=datetime.datetime.strptime(self.extracted[0][i+1][0],self.t_format)\n",
    "            for i in range(stepcount):\n",
    "                timestep[i]-=datetime.datetime.strptime(self.extracted[0][i][0],self.t_format)\n",
    "            self.timestep=timestep\n",
    "            self.allstepseven=all([j==timestep[0] for j in timestep])\n",
    "        else: import sys;sys.exit(\"error from allmatch==0\")\n",
    "    \n",
    "    def timematchcheck(self):\n",
    "        \"\"\"create an attribute self.matchlog that contains a column\n",
    "        for comparing times for series 1 with series 2, then series 1 and series 3, and so on\n",
    "        the rows of self.matchlog  are 1 if all series in that row have the same time and 0 \n",
    "        if any are not a match.\n",
    "        create attribute self.allmatch which is 1 if all values have a matching time and 0 if not.\n",
    "        add feature: handle data that is not synchronized across each row\n",
    "        \"\"\"\n",
    "        matchlog=[]\n",
    "        self.allmatch=1\n",
    "        for i in range(self.datatracker[0]):\n",
    "            matchlog.append([])\n",
    "            for j in range(len(self.datatracker)-1): #j-1 because we have 1 less comparison than series\n",
    "                matchlog[i].append(1) #start all matches as true\n",
    "                if self.extracted[0][i][0]==self.extracted[j+1][i][0]: #j+1 to avoid comparing first series to itself\n",
    "                    matchlog[i][j]=matchlog[i][j]*1 #this will maintian the zero or 1 value\n",
    "                else: \n",
    "                    matchlog[i][j]=0 #this will force the match value to zero if any times don't match.\n",
    "                    self.allmatch=0\n",
    "        self.matchlog=matchlog\n",
    "        \n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "    def extractfromxml(self):\n",
    "        \"\"\"this will take the time and values for each series from the xml to python lists with\n",
    "        observations matched by time or else omitted from the new list. creates a new attribute\n",
    "        called self.extracted with a column for each series and each row contains a (time,value) tuple.\n",
    "        \"\"\"\n",
    "        \"\"\"xmllint --format file1.xml in the linux terminal is used to view the structure of the xml document\n",
    "        \"\"\"\n",
    "        namespace={'ns0':\"http://www.opengis.net/waterml/2.0\",\n",
    "           'ns1':\"http://www.opengis.net/gml/3.2\",\n",
    "           'ns3':\"http://www.w3.org/1999/xlink\",\n",
    "           'ns4':\"http://www.opengis.net/om/2.0\"} \n",
    "        #add feature: automatically make the namespace dictionary automatic by pulling from begining of xml file\n",
    "        extracted=[];j=-1;tracker=[]\n",
    "        for elem in self.root.findall('ns0:observationMember',namespace):\n",
    "            for elem2 in elem.findall('ns4:OM_Observation',namespace):\n",
    "                tracker.append(0)\n",
    "                extracted.append([])\n",
    "                j+=1\n",
    "                for elem3 in elem2.findall('ns4:result',namespace):\n",
    "                    for elem4 in elem3.findall('ns0:MeasurementTimeseries',namespace):\n",
    "                        for elem5 in elem4.findall('ns0:point',namespace):\n",
    "                            for elem6 in elem5.findall('ns0:MeasurementTVP',namespace):\n",
    "                                time=elem6.find('ns0:time',namespace)\n",
    "                                val=elem6.find('ns0:value',namespace)\n",
    "                                extracted[j].append((time.text,val.text))\n",
    "                                tracker[j]+=1\n",
    "        self.extracted=extracted\n",
    "        self.datatracker=tracker #a list of counts of observations for each time,value pair\n",
    "    \n",
    "\n",
    "class Hydrositedatamodel(Hydrositedata):\n",
    "    '''makes grandchild of hydrosite,child of hydrositedata'''\n",
    "    def __init__(self, site, start, end, paramlist, modelfeatures):\n",
    "        super().__init__(site,start,end,paramlist)\n",
    "        self.modelfeatures=modelfeatures\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing RainfallRunoff.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile RainfallRunoff.py\n",
    "\n",
    "import numpy as np\n",
    "class RRtimeseries()\n",
    "'''take in column of dates, rainfall, and runoff and builds distributed lag model'''\n",
    "    def __init__(self,time,rainfall,runoff,maxlag):\n",
    "        self.timeraw=time\n",
    "        self.rainfallraw=ranfall\n",
    "        self.runoffraw=runoff\n",
    "        self.maxlag=maxlag\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
